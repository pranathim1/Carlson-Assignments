
```{r setup, include=FALSE}
library(magrittr) 
library(dplyr)
library(ggplot2)
library(corrplot)
```

## Introduction

A retailer and Advertising & Marketing groups have a joint initiative to better target customers with sponsored search advertising (also known as
“paid search” or just “search advertising”) for products online. The teams cite search advertising as an
important and effective marketing channel for Target.com (and the entire Target firm more broadly). The
effectiveness of search advertising is attributed to the fact that search engines match the ads shown to a
consumer with their current search intent derived from the keyword being used. It subsequently presents an
appropriate list of ads based on factors such as bids placed by the advertisers (e.g., Target) and their
historical performance. The ability to present consumers ads tailored to their search context (as indicated
by the keywords) considerably increases the likelihood that they will click on one these ads. These teams
at Target want to better understand how various features effect the performance of keyword, and are looking
to you for guidance. Moreover, they are concerned that they have been following suboptimal bidding
strategies by bidding too much on keyword terms that do not correspond to customers who are actually
interested (or can be enticed toward) Target products. They fear that because the context of the consumer's
search is not directly observable and its prediction can be nontrivial, they bidding strategy used by
Target.com and the Advertising & Marketing groups could be placing too much value on keywords that are too
ambiguous. This ambiguity results from the fact that the same keyword might refer to different contexts,
and competing advertisers might have different intents while bidding on a particular keyword. Therefore,
you are being asked to conduct an analysis to help provide insight into challenge for the teams.

## Goal 

The goal of this analysis is to explore how various features effect consumer search behavior. Above
this, you will understand the interplay between a keyword’s context and consumers’ search behavior. More
specifically, you will need to ascertain how the breadth of a keyword’s context might affect consumer
behavior and keyword performance. In reality, keyword contextual ambiguity can result in both higher
diversity in ad quality and higher probability of ad irrelevancy. Therefore, how keyword contextual
ambiguity would affect consumer click behavior is unclear. To explore this question, you are going to use a
rich dataset from a major search engine to perform a cross-category analysis and examine which of these two
opposing effects dominates in the context of search advertising.

## Understanding the data 

The keyword level variables are in `keywords.csv`, with the following data dictionary

| Field | Description |
|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|
| num_ads | measures the total number of ads produced for a particular keyword | 
| num_clicks | measures the total number of clicks a particular keyword receives | 
| num_impressions | denotes the total number of times consumers search for a particular keyword in the dataset | 
| num_word | denotes the number of words in the keyword |
| brand | does the keyword refer to a specific brand |
| location | does the keyword refer to a specific location |
| log_trans | a measure of transactional intent, measured by the natural log of the frequency of transactional words that appear in the organic results for this keyword |
| avg_ad_quality | the average quality of ads shown for this keyword, where the quality of an ad is the average click through rate that the ad receives for other keywords |
| avg_num_ads | measures the average number of competing advertisers during an impression, which denotes the competitive intensity for a keyword |
|categoryid | id indicating the keyword's product category |

Additionally, the folder `organic_text` contains a file for each keyword. Each file contains the title and
textual content of the brief description of the top-50-ranked Google organic search results for the given
keyword. This text is meant to be a reasonable approximation of text representing the contextual meaning(s)
of each keyword.

Open the `keywords.csv` data in R 

```{r} 
folder="C:/Users/Pranathi/Desktop/MSBA/Fall/Exploratory data analytics/Assignment 3"
setwd(folder) 
keywords <- read.csv('keywords.csv')
```

## Exploration 
visualize and explore the relationship
between the variables in the data and/or the keywords. create click through rate (ctr) which is the proportion of ad impressions that result in actual clicks.

```{r}
keywords$ctr <- keywords$num_clicks/keywords$num_impressions
cor_pearson <- cor(keywords[sapply(keywords, is.numeric)],use = "everything",method = "pearson")
cor_spearman <- cor(keywords[sapply(keywords, is.numeric)],use = "everything",method = "spearman")
corrplot(cor_pearson, type = "upper", order = "hclust",tl.col = "black", tl.srt = 45)
```

**Using preason correlation to check how two keyword features are linearly increasing relative to another**

**The correlation between num_ads and num_impressions is > 0.8**
**The correlation between clicks and log imp is > 0.5**
**The correlation between log imp and CTR is > -0.6**
**The correlation between ad quality and CTR is >0.5**

**The high correlation between clicks and imp is obvious since on an overall level the number of clicks will increase with increase in number of impressions, even thought the rate of increase in clicks might not be the same as impressions but at an aggregate level the number of clicks will increase**

**The high correlation between num_ads and num_impressions suggest the strategy employed by search engines. Generally the keywords with large number of impressions will have many competitors bidding for ad slots and since they have high number of impressions. It can be inferred that the number of ads per keyword will increase when the number of impressions of keyword increases** 

**Another interesting insight is the high correlation betwen ad quality and CTR, this indicate how good quality of the ad is since it measures the  CTR  ad receives for all other keywords. The quality of ad can be engaging and clear content/visuals which will persuade a user to click it**

```{r}
corrplot(cor_spearman, type = "upper", order = "hclust",tl.col = "black", tl.srt = 45)
```



**Using Spearman correlation to check how two variables are increasing without considering whether the incease is linear or not**


**It is observed that with an increase in clicks - the number of ads, impressons are also increasing. Increase clicks indicate that search keyword is highly related to ads shown.**

**Checking if the keyword feature statistics of brand and non brand keyword differ by plotting the bar plots**

```{r}
cols <- c("querycode","brand","location","categoryid")
keywords[cols] <- lapply(keywords[cols],as.factor)

# Is a branded keyword getting more clicks or impressions
ggplot(keywords,aes(factor(brand),num_clicks)) + geom_boxplot()
ggplot(keywords,aes(factor(brand),num_impressions)) + geom_boxplot()
ggplot(keywords,aes(factor(brand),ctr)) + geom_boxplot()

```

**It is obsered there are no significant differences between the means of the imrpessions, clicks and CTRs**



**Performing chi-square test to check whether distribution of numerical keyword feaures impresisons, clicks and CTR are dependent on groups created by variables like brand, location and category**

**The Null hypoetheses for the test will be that the distribution of CTR is independent of the group**
```{r}
tbl1 <- table(keywords$brand,keywords$ctr)
chisq.test(tbl1)

#location keyword
tbl2 <- table(keywords$location,keywords$ctr)
chisq.test(tbl2)

#length of keyword
tbl3 <- table(keywords$num_word,keywords$ctr)
chisq.test(tbl3)

#category Id
tbl4 <- table(keywords$categoryid,keywords$ctr)
chisq.test(tbl4)

keywords_num <- subset(keywords,select = c("num_ads","num_clicks","num_impressions","log_trans","avg_num_ads","avg_ad_quality","ctr","brand","location","num_word"))

pairs(keywords_num[,1:7], col=factor(keywords_num$brand))

```
**For all the chi-square tests we fail to reject our Null hypotheses**
**This indicates that even though differences could not be sighted from the barplots there exist diffrences between the groups**


**checking the distribution of CTR**
```{r} 
ggplot(keywords) +  stat_density(aes(x=ctr))

```
**The distribution of CTR appears to be bi modal which strongly suggests the presence of intrinsic groups in the data which follow a unimodal and are together giving a bimodal distribution for CTR**



## Modeling 
Understanding how click-through-rate (ctr) is affected by
other features in the `keyword.csv` dataset. Regress ctr on `num_ads`, `num_word`, `brand`, `location`, `log_trans`, `avg_ad_quality` and/or any other interactions or variables you created from your exploration.

```{r}

m1 <- lm(ctr ~ num_ads + num_word + brand + location + log_trans +   avg_ad_quality  + log_imp , data = keywords)
summary(m1)
```
**Inference from the model output**

**The CTR increases with an incease in number of ads**

**The relation between these two cannot be interpreted from the model**

**The association of keyword with a brand tends to lower the CTR**

**The relation between these two cannot be interpreted from the model**

**The CTR increases with increase in frequency of transactional keywords in organic search result**

**The CTR tends to increase the highest for unit change in avg ad quality**

**The CTR is sensitive to ad_quality than other keyword feature as observed from the realtively high estimate of ad_quality compared to other predictor variables**


Turn categoryid into factors and include this into regression

```{r} 
m3 <- lm(ctr ~ num_ads + num_word +brand + location + log_trans +   avg_ad_quality  + log_imp + categoryid , data = keywords)
summary(m3)

```


**The addition of category variable has reduced the error term slightly and has improved the model**

**The category variable as predictor is significant to the model**

**The relationship between the other keyword features and CTR are similar in presence of category variable**

**But in this model we have unique regression equation which will predict the CTR of each category seperately**

**The affect of keyword features will now be interpreted for each category in comparison to the base category which is category 0**

**Example: keeping the category fixed increase in unit ad_quality will increase the CTR significantly by 1.879**



## Topic Modeling 
Analyze how a keyword's context and ambiguity might affect consumer behavior and keyword performance using Latent Dirchlet Allocation algorithm.

```{r, include=FALSE}
# Here are the documentation for packages used in this code:
#https://cran.r-project.org/web/packages/tm/tm.pdf
library(NLP)
library(tm)
#https://cran.r-project.org/web/packages/topicmodels/topicmodels.pdf
library(topicmodels)

# Use the SnowballC package to do stemming.
library(SnowballC) 
```

#pre-processing the text before we run use LDA. 
```{r} 
dirname <- file.path(getwd(),"organic_text")
docs <- Corpus(DirSource(dirname, encoding = "UTF-8"))

# The following steps pre-process the raw text documents. 
# Remove punctuations and numbers because they are generally uninformative. 
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)

# Convert all words to lowercase. 
docs <- tm_map(docs, content_transformer(tolower))

# Remove stopwords such as "a", "the", etc. 
docs <- tm_map(docs, removeWords, stopwords("english"))

# Use the SnowballC package to do stemming. 
docs <- tm_map(docs, stemDocument)

# Remove excess white spaces between words. 
docs <- tm_map(docs, stripWhitespace)

# You can inspect the first document to see what it looks like with 
docs[[1]]$content

# Convert all documents to a term frequency matrix. 
tfm <- DocumentTermMatrix(docs)

# We can check the dimension of this matrix by calling dim() 
print(dim(tfm))
```

#execute LDA to discover topics 
```{r} 
# we run LDA with 20 topics, and use Gibbs sampling as our method for identifying the optimal parameters 
# Note: this make take some time to run (~10 mins)
results <- LDA(tfm, k = 20, method = "Gibbs",control = list(seed = 0))

# Obtain the top w words (i.e., the w most probable words) for each topic, with the optional requirement that their probability is greater than thresh

#feel free to explore with different values of w and thresh
w=10
thresh = 0.01
Terms <- terms(results, w,thresh) 
```


```{r} 
# Obtain the most likely t topic assignments for each document. 
t=1 
Topic <- topics(results,t)

# Get the posterior probability for each document over each topic 
posterior <- posterior(results)[[2]]

# look at the posterior topic distribution for the dth document and plot it visually 
d = 1 
posterior[d,]
barplot(posterior[d,])

# Examine the main topic for document d 
Terms[[which.max(posterior[1,])]]

# Compare the keyword of document d to the terms. keywords$query[d]
keywords$query[1]
```

**Allocation of topic names based on the high frequency words in each topic**

**Topic1 - banks**
**Topic2 - hotels**
**Topic3 - travel**
**Topic4 - carrentals**
**Topic5 - mail**
**Topic6 - contact_search**
**Topic7 - onlinegames**
**Topic8 - real estate**
**Topic9 - company**
**Topic10 - car sale**
**Topic11 - online chat**
**Topic12 - calendar**
**Topic13 - retail products**
**Topic14 - furniture**
**Topic15 - internet applications**
**Topic16 - software**
**Topic17 - dogs**
**Topic18 - mobile services**
**Topic19 - cities**
**Topic20 - Apparel**


```{r}
posterior_df <- data.frame(posterior)
posterior_df$querycode <- sapply(strsplit(rownames(posterior), "_"), "[", 1)
posterior_df[posterior_df$querycode == keywords[keywords$query=='target',1],0:20]

```

**Examining the following keywords**
**1. Yellow Pages**
**2. Pogo**
**3. Toyota**

```{r}
##Yellow Pages
# Keyword = yellow pages; d = 1
Terms[[which.max(posterior_df[posterior_df$querycode == keywords[keywords$query=='yellow pages',1],0:20]
)]]

## The main topic for yellow pages aptly captures the main usage of yellow pages which is contact and adress search
```


```{r}
##POGO

Terms[[which.max(posterior_df[posterior_df$querycode == keywords[keywords$query=='pogo',1],0:20]
)]]

## the main topic for POGO accurately captures the information about POGO. It is a popular online gaming website  and words topic suggest exactly the same
```


```{r}
##TOYOTA

Terms[[which.max(posterior_df[posterior_df$querycode == keywords[keywords$query=='toyota',1],0:20]
)]]

## The main topic for Toyota has ambuity associated with it. The high frequency words of the topic include information realted to cars, pizza and book which increase the ambiguity of the keyword context
```



## Keyword 

Ambiguity Now that we have run LDA and are able to see the document distributions across topics,
we want to use this to quantify the ambiguity of each keyword. We are going to use
[entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) to measure the ambiguity of a
keyword:

```{r} 
entropy <- function(probs)
{

sum = 0  
  for (i in 1:length(probs))
   {
     if (probs[i] != 0) 
        sum = sum  + (probs[i]*log2(probs[i])) 
   }
  return(-sum)
} 
```

Generate a graph of entropy over the interval $[0,1]$.

```{r}

interval <- seq(0,1,0.01)


n=length(interval)

for (i in (1:n))
    {
        interval[i] <- entropy(interval[i]) + entropy(1-interval[i])
}

plot(interval)
```

**The entropy captures the ambiguity of context associated with a keyword. For given keyword organic search text the entropy captures the probaility of presence of the different topics, higher the presence of different topics higher the ambiguity of search results**

```{r}
keyword_entropy <- apply(posterior,1,entropy)

```



```{r}
library(stringr)

querycode <- str_extract(rownames(posterior),"[0-9]+")

df_entropy <- data.frame(querycode,keyword_entropy)

rownames(df_entropy) <- NULL

keywords <- merge(keywords,df_entropy,by="querycode")

```

Re-run the regressions from above, adding this new entropy measure as an additional independent variable
```{r}

fit <- lm(ctr ~ num_ads + num_word + log_trans +   avg_ad_quality +log_imp + keyword_entropy +factor(brand) + factor(location), data = keywords)
summary(fit) 


```

**The entropy variable is significant and can be used to explain the realtionship between CTR and ambiguity**

**The CTR of keyword decreases by for a unit increase in the entropy of the keyword**

**Increase in entropy indicates in ambuity, when the search results are more ambiguous so are the corresponding ads from the users' perspective. the ads shown might not have a contextual fit to what the user is looking for thus with the increase in ambuity of search text the CTR of ads decreases**


## Final Analysis and Recommendations

```{r}
## Exploring the keyword target

Terms[[which.max(posterior_df[posterior_df$querycode ==          keywords[keywords$query=='target',1],0:20]
)]]

keywords[keywords$query == 'target',15]

keywords[keywords$query == 'target',14]


## The main topic for keyword is ambiguos even thoguh it captures the information related to apparel, product, coupon etc but these considering the genric nature of the words in the search result these could correpond to diverse contexts. The search organic text doesn't capture anythign specific to target's offerings or distinctive characterisitcs of target stores**
```

**Analysis of Competitor Keywords and Recommendations for Target**
**k-mart and walmart**
```{r}

Terms[[which.max(posterior_df[posterior_df$querycode ==          keywords[keywords$query=='k-mart',1],0:20]
)]]

keywords[keywords$query == 'k-mart',15]

##K- MART
## The main topic for kohls is exactly same as target but it has less ambiguity due to closenes between the key offerings of 'kohls' and search results. The products 'cloth' , 'shoe', 'shop' closely relate to kohls products and their marketing campaigns which leads to similar topics across the search results**


Terms[[which.max(posterior_df[posterior_df$querycode ==          keywords[keywords$query=='walmart',1],0:20]
)]]

keywords[keywords$query == 'walmart',15]

## the main topic for walmart captures the information to related to the firm and its peformance which is probably covered by the news. It has relatively low ambiguity compared to Target

```

**Comapring CTR of target with competitors**
```{r}
keywords[keywords$query == 'target',14]
keywords[keywords$query == 'k-mart',14]
keywords[keywords$query == 'walmart',14]

## The CTR of k-mart and walmart are relatively very high compared to target
```

**Comparing overall impressions**
```{r}
keywords[keywords$query == 'target',5]
keywords[keywords$query == 'k-mart',5]
keywords[keywords$query == 'walmart',5]

## The number of impressions of target are very high compared to k-mart but have very poor conversion of CTR when compared to k-mart. Considering the high conversion rate of competitiors like k-mart target should bid on competitior words like k-mart in order to reap benefits from the low ambuiguity and high conversion rates


##Comparing to walmart it has both low conversions and low impressios which indicates the high ambiguity of search results i.e users who are using search keyword target are actually looking for something other than target stores due to which they are not interested in the target ads shown. Target should move away from inversting in these kinds of ambiguous keywords**

##Instead of placing bids on words like 'target' it should focus on words which correspond to products, offerings etc of its competitors (which are also offered by target) and have a good historical performance in terms of CTR.**
```
